/**
 * Tests for ExportService
 * Task T057 [Phase 5 - User Story 3] - 48-Column Complete CSV Format
 * Task T060 [Phase 5 - User Story 3] - Performance Tests
 *
 * Tests the streaming CSV export functionality for handling large datasets.
 *
 * 48-Column Complete Format Requirements (T057):
 * - Core Columns (10): url, status, confidence_score, confidence_band, eliminated_at_layer,
 *   processing_time_ms, total_cost, layer1_passed, layer2_passed, layer3_passed
 * - Layer 1 Columns (5): l1_tld_type, l1_tld_value, l1_domain_classification,
 *   l1_pattern_matches, l1_target_profile
 * - Layer 2 Columns (10): l2_publication_score, l2_product_offering_score, l2_layout_score,
 *   l2_navigation_score, l2_monetization_score, l2_keywords_found, l2_ad_networks,
 *   l2_content_signals, l2_reasoning, l2_passed
 * - Layer 3 Columns (15): l3_classification, l3_design_quality_score, l3_design_quality_indicators,
 *   l3_authority_score, l3_authority_indicators, l3_presentation_score, l3_presentation_indicators,
 *   l3_originality_score, l3_originality_indicators, l3_llm_provider, l3_llm_model,
 *   l3_llm_cost, l3_reasoning, l3_tokens_input, l3_tokens_output
 * - Metadata Columns (8): job_id, url_id, retry_count, last_error, processed_at,
 *   created_at, updated_at, reviewer_notes
 *
 * Total: 48 columns (10 + 5 + 10 + 15 + 8)
 *
 * Format Requirements:
 * - All columns follow snake_case naming convention
 * - Multi-value fields: comma-separated, properly escaped
 * - NULL handling: Pre-migration data and eliminated layers
 * - Excel compatibility: UTF-8 BOM, CRLF, RFC 4180 quoting
 *
 * Performance Requirements (T060):
 * - Export 10,000 URLs in less than 5 seconds
 * - Use streaming (not load all in memory)
 * - Process in 100-row batches
 * - Support filtering while maintaining performance
 *
 * Test Scenarios:
 * 1. Column Count: Verify 48 columns with correct names and order (T057)
 * 2. Data Types: Verify numeric, boolean, string, date formatting (T057)
 * 3. Multi-value Fields: Comma-separated lists, properly escaped (T057)
 * 4. NULL Handling: Pre-migration data, eliminated layers (T057)
 * 5. Test Scenarios: Approved, Layer 1/2/3 eliminated, rejected, pre-migration (T057)
 * 6. Performance: 10k row export completes in < 5 seconds (T060)
 * 7. Streaming: Uses batches of 100 rows (T060)
 * 8. Memory: No memory spike during export (T060)
 */

import { Test, TestingModule } from '@nestjs/testing';
import { Readable } from 'stream';
import { SupabaseService } from '../../supabase/supabase.service';
import { UrlResult } from '@website-scraper/shared';

/**
 * Mock SupabaseService for testing
 */
class MockSupabaseService {
  private mockClient: any;

  constructor() {
    this.mockClient = {
      from: jest.fn().mockReturnThis(),
      select: jest.fn().mockReturnThis(),
      eq: jest.fn().mockReturnThis(),
      order: jest.fn().mockReturnThis(),
      range: jest.fn().mockReturnThis(),
    };
  }

  getClient() {
    return this.mockClient;
  }

  getMockClient() {
    return this.mockClient;
  }
}

/**
 * ExportService - To be implemented
 * This is a placeholder for the actual service that will be created in T061
 */
class ExportService {
  constructor(private readonly supabase: SupabaseService) {}

  /**
   * Stream CSV export with batching
   * To be implemented in T061
   */
  async streamCSVExport(
    jobId: string,
    format: 'complete' | 'summary' | 'layer1' | 'layer2' | 'layer3',
    filters?: {
      status?: string;
      confidence?: string;
      layer?: string;
    }
  ): Promise<Readable> {
    // TODO: Implement in T061
    throw new Error('Not implemented yet - TDD approach');
  }

  /**
   * Escape a single CSV field per RFC 4180
   * To be implemented in T061
   */
  escapeCSVField(value: string | null | undefined): string {
    // TODO: Implement in T061
    throw new Error('Not implemented yet - TDD approach');
  }

  /**
   * Format a complete CSV row from array of values
   * To be implemented in T061
   */
  formatCSVRow(values: Array<string | null | undefined>): string {
    // TODO: Implement in T061
    throw new Error('Not implemented yet - TDD approach');
  }

  /**
   * Generate CSV with UTF-8 BOM and CRLF line endings
   * To be implemented in T061
   */
  generateCSVWithBOM(rows: string[]): string {
    // TODO: Implement in T061
    throw new Error('Not implemented yet - TDD approach');
  }
}

describe('ExportService - Performance Tests (T060)', () => {
  let exportService: ExportService;
  let mockSupabaseService: MockSupabaseService;
  let mockSupabaseClient: any;

  beforeAll(async () => {
    mockSupabaseService = new MockSupabaseService();
    mockSupabaseClient = mockSupabaseService.getMockClient();

    const moduleFixture: TestingModule = await Test.createTestingModule({
      providers: [
        ExportService,
        {
          provide: SupabaseService,
          useValue: mockSupabaseService,
        },
      ],
    }).compile();

    exportService = moduleFixture.get<ExportService>(ExportService);
  });

  beforeEach(() => {
    jest.clearAllMocks();
  });

  /**
   * Helper function to generate mock UrlResult data
   */
  function generateMockUrlResult(index: number): UrlResult {
    const statuses = ['approved', 'rejected', 'queue_overflow', 'pending', 'processing', 'failed', 'timeout'];
    const confidenceBands = ['very-high', 'high', 'medium', 'low', 'very-low', null];
    const eliminatedLayers = ['layer1', 'layer2', 'layer3', 'passed_all', null];

    const status = statuses[index % statuses.length] as UrlResult['status'];
    const confidenceBand = confidenceBands[index % confidenceBands.length] as UrlResult['confidence_band'];
    const eliminatedAtLayer = eliminatedLayers[index % eliminatedLayers.length] as UrlResult['eliminated_at_layer'];

    const hasLayer1 = true; // All URLs go through Layer 1
    const hasLayer2 = eliminatedAtLayer !== 'layer1'; // Only if passed Layer 1
    const hasLayer3 = eliminatedAtLayer === 'layer3' || eliminatedAtLayer === 'passed_all'; // Only if reached Layer 3

    return {
      id: `result-${index.toString().padStart(10, '0')}`,
      url: `https://example-${index}.com`,
      job_id: 'test-job-id',
      url_id: `url-${index.toString().padStart(10, '0')}`,
      status,
      confidence_score: hasLayer3 ? Math.random() : null,
      confidence_band: confidenceBand,
      eliminated_at_layer: eliminatedAtLayer,
      processing_time_ms: Math.floor(Math.random() * 5000) + 1000,
      total_cost: Math.random() * 0.01,
      retry_count: Math.floor(Math.random() * 4),
      last_error: Math.random() > 0.8 ? 'Timeout error' : null,
      last_retry_at: Math.random() > 0.8 ? new Date() : null,
      processed_at: new Date(),
      reviewer_notes: Math.random() > 0.9 ? 'Manual review note' : null,
      created_at: new Date(),
      updated_at: new Date(),

      // Layer 1 Factors - Always present
      layer1_factors: hasLayer1 ? {
        tld_type: ['gtld', 'cctld', 'custom'][index % 3] as 'gtld' | 'cctld' | 'custom',
        tld_value: ['.com', '.net', '.org', '.io', '.co'][index % 5],
        domain_classification: ['commercial', 'personal', 'institutional', 'spam'][index % 4] as 'commercial' | 'personal' | 'institutional' | 'spam',
        pattern_matches: index % 3 === 0 ? ['affiliate-link'] : [],
        target_profile: {
          type: ['B2B software', 'e-commerce', 'content site', 'personal blog'][index % 4],
          confidence: Math.random(),
        },
        reasoning: `Layer 1 reasoning for URL ${index}`,
        passed: eliminatedAtLayer !== 'layer1',
      } : null,

      // Layer 2 Factors - Only if passed Layer 1
      layer2_factors: hasLayer2 ? {
        publication_score: Math.random(),
        module_scores: {
          product_offering: Math.random(),
          layout_quality: Math.random(),
          navigation_complexity: Math.random(),
          monetization_indicators: Math.random(),
        },
        keywords_found: ['enterprise', 'solution', 'platform'],
        ad_networks_detected: index % 5 === 0 ? ['Google Ads'] : [],
        content_signals: {
          has_blog: index % 2 === 0,
          has_press_releases: index % 3 === 0,
          has_whitepapers: index % 4 === 0,
          has_case_studies: index % 5 === 0,
        },
        reasoning: `Layer 2 reasoning for URL ${index}`,
        passed: eliminatedAtLayer !== 'layer2',
      } : null,

      // Layer 3 Factors - Only if reached Layer 3
      layer3_factors: hasLayer3 ? {
        classification: eliminatedAtLayer === 'passed_all' ? 'accepted' : 'rejected',
        sophistication_signals: {
          design_quality: {
            score: Math.random(),
            indicators: ['Modern interface', 'Consistent branding'],
          },
          authority_indicators: {
            score: Math.random(),
            indicators: ['Customer testimonials', 'Industry certifications'],
          },
          professional_presentation: {
            score: Math.random(),
            indicators: ['Well-structured content', 'Clear value proposition'],
          },
          content_originality: {
            score: Math.random(),
            indicators: ['Original case studies', 'Unique product features'],
          },
        },
        llm_provider: 'anthropic',
        model_version: 'claude-3-opus-20240229',
        cost_usd: Math.random() * 0.01,
        reasoning: `Layer 3 reasoning for URL ${index}`,
        tokens_used: {
          input: Math.floor(Math.random() * 3000) + 1000,
          output: Math.floor(Math.random() * 1000) + 500,
        },
        processing_time_ms: Math.floor(Math.random() * 3000) + 1000,
      } : null,
    };
  }

  /**
   * Helper function to generate batch of mock results
   */
  function generateMockBatch(startIndex: number, batchSize: number): UrlResult[] {
    const batch: UrlResult[] = [];
    for (let i = 0; i < batchSize; i++) {
      batch.push(generateMockUrlResult(startIndex + i));
    }
    return batch;
  }

  describe('Scenario 1: Performance - 10k row export completes in < 5 seconds', () => {
    it('should export 10,000 rows in less than 5 seconds', async () => {
      // Arrange - Mock Supabase to return 10,000 results in batches
      const totalRows = 10000;
      const batchSize = 100;
      let currentBatch = 0;

      // Mock the range() method to return data in batches
      mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
        return {
          then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
            const batchData = generateMockBatch(start, end - start + 1);
            callback({ data: batchData, error: null });
          },
        };
      });

      // Act - Measure export time
      const startTime = Date.now();

      try {
        await exportService.streamCSVExport('test-job-id', 'complete');

        // This should fail until implementation is complete (TDD approach)
        fail('Expected streamCSVExport to throw "Not implemented yet" error');
      } catch (error) {
        // Expected to fail with "Not implemented yet" error during TDD phase
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }

      const elapsedTime = Date.now() - startTime;

      // Assert - Verify performance (will be tested after implementation)
      // TODO: Uncomment after T061 implementation
      // expect(elapsedTime).toBeLessThan(5000);

      console.log(`[T060 Performance Test] Current elapsed time: ${elapsedTime}ms (Target: < 5000ms)`);
    });

    it('should maintain performance with NULL factor values (pre-migration data)', async () => {
      // Test performance with URLs that have NULL layer factors
      const totalRows = 10000;

      // Generate mock data with NULL factors
      const mockResults = Array.from({ length: totalRows }, (_, index) => ({
        ...generateMockUrlResult(index),
        layer1_factors: null,
        layer2_factors: null,
        layer3_factors: null,
      }));

      mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
        return {
          then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
            const batchData = mockResults.slice(start, end + 1);
            callback({ data: batchData, error: null });
          },
        };
      });

      const startTime = Date.now();

      try {
        await exportService.streamCSVExport('test-job-id', 'complete');
        fail('Expected streamCSVExport to throw "Not implemented yet" error');
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }

      const elapsedTime = Date.now() - startTime;

      // TODO: Uncomment after T061 implementation
      // expect(elapsedTime).toBeLessThan(5000);

      console.log(`[T060 NULL Factors Test] Current elapsed time: ${elapsedTime}ms (Target: < 5000ms)`);
    });
  });

  describe('Scenario 2: Streaming - Uses batches of 100 rows', () => {
    it('should process data in batches of 100 rows', async () => {
      // Arrange
      const batchSize = 100;
      let batchCount = 0;

      mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
        batchCount++;
        const actualBatchSize = end - start + 1;
        expect(actualBatchSize).toBeLessThanOrEqual(batchSize);

        return {
          then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
            const batchData = generateMockBatch(start, actualBatchSize);
            callback({ data: batchData, error: null });
          },
        };
      });

      // Act
      try {
        await exportService.streamCSVExport('test-job-id', 'complete');
        fail('Expected streamCSVExport to throw "Not implemented yet" error');
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }

      // Assert - Verify batching behavior (after implementation)
      // TODO: Uncomment after T061 implementation
      // expect(batchCount).toBe(100); // 10,000 rows / 100 per batch = 100 batches
    });

    it('should not load entire dataset in memory at once', async () => {
      // This test verifies streaming behavior by checking memory usage patterns
      const initialMemory = process.memoryUsage().heapUsed;

      mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
        return {
          then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
            const batchData = generateMockBatch(start, end - start + 1);
            callback({ data: batchData, error: null });
          },
        };
      });

      try {
        await exportService.streamCSVExport('test-job-id', 'complete');
        fail('Expected streamCSVExport to throw "Not implemented yet" error');
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }

      const finalMemory = process.memoryUsage().heapUsed;
      const memoryIncrease = finalMemory - initialMemory;
      const memoryIncreaseMB = memoryIncrease / 1024 / 1024;

      // TODO: Uncomment after T061 implementation
      // Memory increase should be minimal if streaming properly (< 10MB for metadata)
      // If loading all 10k rows in memory, would be 50-100MB+
      // expect(memoryIncreaseMB).toBeLessThan(10);

      console.log(`[T060 Memory Test] Memory increase: ${memoryIncreaseMB.toFixed(2)}MB (Target: < 10MB)`);
    });
  });

  describe('Scenario 3: Output - Contains 10,001 lines (1 header + 10k data)', () => {
    it('should generate CSV with header row plus 10,000 data rows', async () => {
      // Arrange
      mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
        return {
          then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
            const batchData = generateMockBatch(start, end - start + 1);
            callback({ data: batchData, error: null });
          },
        };
      });

      // Act
      try {
        const stream = await exportService.streamCSVExport('test-job-id', 'complete');

        // Consume stream and count lines
        let lineCount = 0;
        let csvContent = '';

        for await (const chunk of stream) {
          csvContent += chunk.toString();
        }

        lineCount = csvContent.split('\n').filter(line => line.trim().length > 0).length;

        // Assert
        expect(lineCount).toBe(10001); // 1 header + 10,000 data rows

      } catch (error) {
        // Expected to fail during TDD phase
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('should include header row with all column names', async () => {
      // Arrange
      mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
        return {
          then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
            const batchData = generateMockBatch(start, Math.min(100, end - start + 1));
            callback({ data: batchData, error: null });
          },
        };
      });

      // Act
      try {
        const stream = await exportService.streamCSVExport('test-job-id', 'complete');

        let csvContent = '';
        for await (const chunk of stream) {
          csvContent += chunk.toString();
          // Break after first chunk to just check header
          break;
        }

        const firstLine = csvContent.split('\n')[0];

        // Assert - Verify header contains expected columns
        // Complete format should have 48 columns (10 core + 5 L1 + 10 L2 + 15 L3)
        expect(firstLine).toContain('URL');
        expect(firstLine).toContain('Status');
        expect(firstLine).toContain('Confidence Score');
        expect(firstLine).toContain('TLD Type'); // Layer 1
        expect(firstLine).toContain('Publication Score'); // Layer 2
        expect(firstLine).toContain('Classification'); // Layer 3

      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });
  });

  describe('Scenario 4: Formats - All 5 formats maintain performance', () => {
    const formats: Array<'complete' | 'summary' | 'layer1' | 'layer2' | 'layer3'> = [
      'complete',  // 48 columns
      'summary',   // 7 columns
      'layer1',    // 15 columns
      'layer2',    // 20 columns
      'layer3',    // 25 columns
    ];

    formats.forEach(format => {
      it(`should export 10k rows in < 5s for ${format} format`, async () => {
        // Arrange
        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = generateMockBatch(start, end - start + 1);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        const startTime = Date.now();

        try {
          await exportService.streamCSVExport('test-job-id', format);
          fail('Expected streamCSVExport to throw "Not implemented yet" error');
        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }

        const elapsedTime = Date.now() - startTime;

        // TODO: Uncomment after T061 implementation
        // expect(elapsedTime).toBeLessThan(5000);

        console.log(`[T060 ${format} Format] Current elapsed time: ${elapsedTime}ms (Target: < 5000ms)`);
      });
    });
  });

  describe('Scenario 5: Filtering - Filtered export maintains performance', () => {
    it('should export filtered results (approved only) in < 5s', async () => {
      // Arrange - Mock filtered data (only approved URLs)
      mockSupabaseClient.eq.mockReturnThis();
      mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
        return {
          then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
            const batchData = generateMockBatch(start, end - start + 1).map(result => ({
              ...result,
              status: 'approved' as const,
            }));
            callback({ data: batchData, error: null });
          },
        };
      });

      // Act
      const startTime = Date.now();

      try {
        await exportService.streamCSVExport('test-job-id', 'complete', {
          status: 'approved',
        });
        fail('Expected streamCSVExport to throw "Not implemented yet" error');
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }

      const elapsedTime = Date.now() - startTime;

      // TODO: Uncomment after T061 implementation
      // expect(elapsedTime).toBeLessThan(5000);

      console.log(`[T060 Filtered Export] Current elapsed time: ${elapsedTime}ms (Target: < 5000ms)`);
    });

    it('should export filtered results (high confidence only) in < 5s', async () => {
      // Arrange
      mockSupabaseClient.eq.mockReturnThis();
      mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
        return {
          then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
            const batchData = generateMockBatch(start, end - start + 1).map(result => ({
              ...result,
              confidence_band: 'high' as const,
            }));
            callback({ data: batchData, error: null });
          },
        };
      });

      // Act
      const startTime = Date.now();

      try {
        await exportService.streamCSVExport('test-job-id', 'complete', {
          confidence: 'high',
        });
        fail('Expected streamCSVExport to throw "Not implemented yet" error');
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }

      const elapsedTime = Date.now() - startTime;

      // TODO: Uncomment after T061 implementation
      // expect(elapsedTime).toBeLessThan(5000);

      console.log(`[T060 High Confidence Filter] Current elapsed time: ${elapsedTime}ms (Target: < 5000ms)`);
    });

    it('should export filtered results (passed_all only) in < 5s', async () => {
      // Arrange
      mockSupabaseClient.eq.mockReturnThis();
      mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
        return {
          then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
            const batchData = generateMockBatch(start, end - start + 1).map(result => ({
              ...result,
              eliminated_at_layer: 'passed_all' as const,
            }));
            callback({ data: batchData, error: null });
          },
        };
      });

      // Act
      const startTime = Date.now();

      try {
        await exportService.streamCSVExport('test-job-id', 'complete', {
          layer: 'passed_all',
        });
        fail('Expected streamCSVExport to throw "Not implemented yet" error');
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }

      const elapsedTime = Date.now() - startTime;

      // TODO: Uncomment after T061 implementation
      // expect(elapsedTime).toBeLessThan(5000);

      console.log(`[T060 Passed All Filter] Current elapsed time: ${elapsedTime}ms (Target: < 5000ms)`);
    });
  });

  describe('Edge Cases and Error Handling', () => {
    it('should handle empty result set efficiently', async () => {
      // Arrange - Mock empty results
      mockSupabaseClient.range.mockImplementation(() => {
        return {
          then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
            callback({ data: [], error: null });
          },
        };
      });

      // Act
      try {
        const stream = await exportService.streamCSVExport('test-job-id', 'complete');

        let csvContent = '';
        for await (const chunk of stream) {
          csvContent += chunk.toString();
        }

        const lineCount = csvContent.split('\n').filter(line => line.trim().length > 0).length;

        // Assert - Should only have header row
        expect(lineCount).toBe(1);

      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('should handle database errors gracefully', async () => {
      // Arrange - Mock database error
      mockSupabaseClient.range.mockImplementation(() => {
        return {
          then: (callback: (result: { data: null; error: { message: string } }) => void) => {
            callback({ data: null, error: { message: 'Database connection error' } });
          },
        };
      });

      // Act & Assert
      try {
        await exportService.streamCSVExport('test-job-id', 'complete');
        fail('Expected streamCSVExport to throw error');
      } catch (error) {
        // During TDD phase, will throw "Not implemented yet"
        // After implementation, should handle database errors gracefully
        expect((error as Error).message).toBeTruthy();
      }
    });
  });

  // ============================================================================
  // T058 [P] [US3] - All CSV Format Options Tests
  // ============================================================================

  describe('T058: All CSV Format Options', () => {
    /**
     * Helper to generate mock result set with varied layer eliminations
     */
    function generateMixedResults(count: number): UrlResult[] {
      const results: UrlResult[] = [];

      for (let i = 0; i < count; i++) {
        const mockResult = generateMockUrlResult(i);
        results.push(mockResult);
      }

      return results;
    }

    /**
     * Helper to count CSV columns from a header row
     */
    function countCSVColumns(headerLine: string): number {
      // Simple CSV column counter - split by comma (ignoring quoted commas)
      const columns = headerLine.match(/(?:^|,)(?:[^",]*|"[^"]*")+/g) || [];
      return columns.length;
    }

    /**
     * Helper to extract CSV columns from header row
     */
    function extractCSVColumns(headerLine: string): string[] {
      // Extract column names from CSV header
      const columns = headerLine.match(/(?:^|,)(?:"([^"]*)"|([^",]*))/g) || [];
      return columns.map(col => col.replace(/^,/, '').replace(/^"|"$/g, '').trim());
    }

    describe('Test 1: Complete Format Export', () => {
      it('should export with exactly 48 columns', async () => {
        // Arrange - Mock 100 mixed results
        const mockResults = generateMixedResults(100);

        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = mockResults.slice(start, end + 1);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'complete');

          let csvContent = '';
          for await (const chunk of stream) {
            csvContent += chunk.toString();
          }

          const lines = csvContent.split('\n').filter(line => line.trim().length > 0);
          const headerLine = lines[0];
          const columnCount = countCSVColumns(headerLine);

          // Assert
          expect(columnCount).toBe(48); // 10 core + 5 L1 + 10 L2 + 15 L3 + 8 other = 48
          expect(lines.length).toBe(101); // 1 header + 100 data rows

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });

      it('should include all layer columns in header', async () => {
        // Arrange
        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = generateMockBatch(start, 10);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'complete');

          let firstChunk = '';
          for await (const chunk of stream) {
            firstChunk += chunk.toString();
            break; // Just get first chunk with header
          }

          const headerLine = firstChunk.split('\n')[0];
          const columns = extractCSVColumns(headerLine);

          // Assert - Verify key columns from each layer are present
          // Core columns
          expect(columns).toContain('URL');
          expect(columns).toContain('Status');
          expect(columns).toContain('Confidence Score');
          expect(columns).toContain('Eliminated At Layer');
          expect(columns).toContain('Processing Time (ms)');
          expect(columns).toContain('Total Cost (USD)');

          // Layer 1 columns
          expect(columns).toContain('L1: TLD Type');
          expect(columns).toContain('L1: TLD Value');
          expect(columns).toContain('L1: Domain Classification');
          expect(columns).toContain('L1: Pattern Matches');
          expect(columns).toContain('L1: Target Profile Type');

          // Layer 2 columns
          expect(columns).toContain('L2: Publication Score');
          expect(columns).toContain('L2: Product Offering Score');
          expect(columns).toContain('L2: Layout Quality Score');
          expect(columns).toContain('L2: Keywords Found');
          expect(columns).toContain('L2: Ad Networks Detected');

          // Layer 3 columns
          expect(columns).toContain('L3: Classification');
          expect(columns).toContain('L3: Design Quality Score');
          expect(columns).toContain('L3: Authority Indicators Score');
          expect(columns).toContain('L3: Content Originality Score');
          expect(columns).toContain('L3: LLM Provider');

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });
    });

    describe('Test 2: Summary Format Export', () => {
      it('should export with exactly 7 columns', async () => {
        // Arrange
        const mockResults = generateMixedResults(100);

        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = mockResults.slice(start, end + 1);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'summary');

          let csvContent = '';
          for await (const chunk of stream) {
            csvContent += chunk.toString();
          }

          const lines = csvContent.split('\n').filter(line => line.trim().length > 0);
          const headerLine = lines[0];
          const columnCount = countCSVColumns(headerLine);

          // Assert
          expect(columnCount).toBe(7); // Only summary columns
          expect(lines.length).toBe(101); // 1 header + 100 data rows

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });

      it('should only include summary columns in header', async () => {
        // Arrange
        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = generateMockBatch(start, 10);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'summary');

          let firstChunk = '';
          for await (const chunk of stream) {
            firstChunk += chunk.toString();
            break;
          }

          const headerLine = firstChunk.split('\n')[0];
          const columns = extractCSVColumns(headerLine);

          // Assert - Verify only 7 summary columns
          expect(columns.length).toBe(7);
          expect(columns).toContain('URL');
          expect(columns).toContain('Status');
          expect(columns).toContain('Confidence Score');
          expect(columns).toContain('Eliminated At Layer');
          expect(columns).toContain('Processing Time (ms)');
          expect(columns).toContain('Total Cost (USD)');
          expect(columns).toContain('Summary Reason');

          // Should NOT contain any layer-specific columns
          expect(columns).not.toContain('L1: TLD Type');
          expect(columns).not.toContain('L2: Publication Score');
          expect(columns).not.toContain('L3: Classification');

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });

      it('should include summary_reason field for all results', async () => {
        // Arrange
        const mockResults = generateMixedResults(50);

        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = mockResults.slice(start, end + 1);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'summary');

          let csvContent = '';
          for await (const chunk of stream) {
            csvContent += chunk.toString();
          }

          const lines = csvContent.split('\n').filter(line => line.trim().length > 0);

          // Assert - Every data row should have a summary_reason (last column)
          for (let i = 1; i < lines.length; i++) {
            const dataRow = lines[i];
            const columns = dataRow.split(',');
            expect(columns.length).toBe(7);

            // Summary reason should be the last column and not empty
            const summaryReason = columns[6];
            expect(summaryReason).toBeTruthy();
          }

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });
    });

    describe('Test 3: Layer1 Format Export', () => {
      it('should export with exactly 15 columns', async () => {
        // Arrange
        const mockResults = generateMixedResults(100);

        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = mockResults.slice(start, end + 1);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'layer1');

          let csvContent = '';
          for await (const chunk of stream) {
            csvContent += chunk.toString();
          }

          const lines = csvContent.split('\n').filter(line => line.trim().length > 0);
          const headerLine = lines[0];
          const columnCount = countCSVColumns(headerLine);

          // Assert
          expect(columnCount).toBe(15); // 10 core + 5 L1
          expect(lines.length).toBe(101);

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });

      it('should include core and Layer1 columns but not Layer2/3', async () => {
        // Arrange
        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = generateMockBatch(start, 10);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'layer1');

          let firstChunk = '';
          for await (const chunk of stream) {
            firstChunk += chunk.toString();
            break;
          }

          const headerLine = firstChunk.split('\n')[0];
          const columns = extractCSVColumns(headerLine);

          // Assert - Verify Layer 1 columns present
          expect(columns).toContain('URL');
          expect(columns).toContain('Status');
          expect(columns).toContain('L1: TLD Type');
          expect(columns).toContain('L1: Domain Classification');
          expect(columns).toContain('L1: Target Profile Type');

          // Should NOT contain Layer 2 or Layer 3 columns
          expect(columns).not.toContain('L2: Publication Score');
          expect(columns).not.toContain('L2: Keywords Found');
          expect(columns).not.toContain('L3: Classification');
          expect(columns).not.toContain('L3: Design Quality Score');

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });

      it('should populate Layer1 data for all results', async () => {
        // Arrange - All URLs go through Layer 1
        const mockResults = generateMixedResults(50);

        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = mockResults.slice(start, end + 1);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'layer1');

          let csvContent = '';
          for await (const chunk of stream) {
            csvContent += chunk.toString();
          }

          const lines = csvContent.split('\n').filter(line => line.trim().length > 0);

          // Assert - Every data row should have Layer 1 data populated
          // (Not checking specific values, just that Layer 1 columns have data)
          for (let i = 1; i < lines.length; i++) {
            const dataRow = lines[i];
            expect(dataRow.length).toBeGreaterThan(0);
          }

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });
    });

    describe('Test 4: Layer2 Format Export', () => {
      it('should export with 20-25 columns', async () => {
        // Arrange
        const mockResults = generateMixedResults(100);

        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = mockResults.slice(start, end + 1);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'layer2');

          let csvContent = '';
          for await (const chunk of stream) {
            csvContent += chunk.toString();
          }

          const lines = csvContent.split('\n').filter(line => line.trim().length > 0);
          const headerLine = lines[0];
          const columnCount = countCSVColumns(headerLine);

          // Assert
          expect(columnCount).toBeGreaterThanOrEqual(20);
          expect(columnCount).toBeLessThanOrEqual(25);
          expect(lines.length).toBe(101);

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });

      it('should include core + Layer1 + Layer2 columns but not Layer3', async () => {
        // Arrange
        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = generateMockBatch(start, 10);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'layer2');

          let firstChunk = '';
          for await (const chunk of stream) {
            firstChunk += chunk.toString();
            break;
          }

          const headerLine = firstChunk.split('\n')[0];
          const columns = extractCSVColumns(headerLine);

          // Assert - Verify Layer 1 and Layer 2 columns present
          expect(columns).toContain('URL');
          expect(columns).toContain('L1: TLD Type');
          expect(columns).toContain('L1: Domain Classification');
          expect(columns).toContain('L2: Publication Score');
          expect(columns).toContain('L2: Product Offering Score');
          expect(columns).toContain('L2: Layout Quality Score');
          expect(columns).toContain('L2: Keywords Found');

          // Should NOT contain Layer 3 columns
          expect(columns).not.toContain('L3: Classification');
          expect(columns).not.toContain('L3: Design Quality Score');
          expect(columns).not.toContain('L3: LLM Provider');

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });
    });

    describe('Test 5: Layer3 Format Export', () => {
      it('should export with 25+ columns', async () => {
        // Arrange
        const mockResults = generateMixedResults(100);

        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = mockResults.slice(start, end + 1);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'layer3');

          let csvContent = '';
          for await (const chunk of stream) {
            csvContent += chunk.toString();
          }

          const lines = csvContent.split('\n').filter(line => line.trim().length > 0);
          const headerLine = lines[0];
          const columnCount = countCSVColumns(headerLine);

          // Assert
          expect(columnCount).toBeGreaterThanOrEqual(25);
          expect(lines.length).toBe(101);

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });

      it('should include all layer columns', async () => {
        // Arrange
        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = generateMockBatch(start, 10);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'layer3');

          let firstChunk = '';
          for await (const chunk of stream) {
            firstChunk += chunk.toString();
            break;
          }

          const headerLine = firstChunk.split('\n')[0];
          const columns = extractCSVColumns(headerLine);

          // Assert - Verify all layer columns present
          expect(columns).toContain('URL');
          expect(columns).toContain('L1: TLD Type');
          expect(columns).toContain('L1: Domain Classification');
          expect(columns).toContain('L2: Publication Score');
          expect(columns).toContain('L2: Keywords Found');
          expect(columns).toContain('L3: Classification');
          expect(columns).toContain('L3: Design Quality Score');
          expect(columns).toContain('L3: Authority Indicators Score');
          expect(columns).toContain('L3: Content Originality Score');
          expect(columns).toContain('L3: LLM Provider');

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });

      it('should only populate Layer3 data where URL reached Layer 3', async () => {
        // Arrange - Mixed results with different elimination layers
        const mockResults = generateMixedResults(100);

        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = mockResults.slice(start, end + 1);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'layer3');

          let csvContent = '';
          for await (const chunk of stream) {
            csvContent += chunk.toString();
          }

          const lines = csvContent.split('\n').filter(line => line.trim().length > 0);

          // Assert - Results eliminated at Layer1 or Layer2 should have empty Layer3 fields
          // This is a structural test - actual validation happens during implementation
          expect(lines.length).toBe(101);

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });
    });

    describe('Test 6: Format Consistency', () => {
      it('should export same 100 results in all 5 formats with consistent row count', async () => {
        // Arrange - Same dataset for all formats
        const mockResults = generateMixedResults(100);

        const formats: Array<'complete' | 'summary' | 'layer1' | 'layer2' | 'layer3'> = [
          'complete',
          'summary',
          'layer1',
          'layer2',
          'layer3',
        ];

        // Act & Assert - Export in all formats and verify structure
        for (const format of formats) {
          mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
            return {
              then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
                const batchData = mockResults.slice(start, end + 1);
                callback({ data: batchData, error: null });
              },
            };
          });

          try {
            const stream = await exportService.streamCSVExport('test-job-id', format);

            let csvContent = '';
            for await (const chunk of stream) {
              csvContent += chunk.toString();
            }

            const lines = csvContent.split('\n').filter(line => line.trim().length > 0);

            // All formats should have same row count (header + 100 data rows)
            expect(lines.length).toBe(101);

          } catch (error) {
            expect((error as Error).message).toBe('Not implemented yet - TDD approach');
          }
        }
      });
    });

    describe('Test 7: Format with Filters', () => {
      it('should apply filters correctly in Complete format', async () => {
        // Arrange - Filter for approved only
        const mockResults = generateMixedResults(200).map((r, i) => ({
          ...r,
          status: (i % 2 === 0 ? 'approved' : 'rejected') as UrlResult['status'],
        }));

        const filteredResults = mockResults.filter(r => r.status === 'approved');

        mockSupabaseClient.eq.mockReturnThis();
        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = filteredResults.slice(start, end + 1);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'complete', {
            status: 'approved',
          });

          let csvContent = '';
          for await (const chunk of stream) {
            csvContent += chunk.toString();
          }

          const lines = csvContent.split('\n').filter(line => line.trim().length > 0);
          const headerLine = lines[0];
          const columnCount = countCSVColumns(headerLine);

          // Assert
          expect(columnCount).toBe(48); // Complete format columns
          expect(lines.length).toBe(101); // 1 header + 100 approved results

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });

      it('should apply filters correctly in Summary format', async () => {
        // Arrange - Filter for high confidence
        const mockResults = generateMixedResults(200).map((r, i) => ({
          ...r,
          confidence_band: (i % 3 === 0 ? 'high' : 'low') as UrlResult['confidence_band'],
        }));

        const filteredResults = mockResults.filter(r => r.confidence_band === 'high');

        mockSupabaseClient.eq.mockReturnThis();
        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = filteredResults.slice(start, end + 1);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'summary', {
            confidence: 'high',
          });

          let csvContent = '';
          for await (const chunk of stream) {
            csvContent += chunk.toString();
          }

          const lines = csvContent.split('\n').filter(line => line.trim().length > 0);
          const headerLine = lines[0];
          const columnCount = countCSVColumns(headerLine);

          // Assert
          expect(columnCount).toBe(7); // Summary format columns
          expect(lines.length).toBeGreaterThan(1); // Header + filtered results

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });

      it('should maintain column structure with filters applied', async () => {
        // Arrange - Multiple filters
        const mockResults = generateMixedResults(100)
          .filter(r => r.status === 'approved')
          .filter(r => r.confidence_band === 'high');

        mockSupabaseClient.eq.mockReturnThis();
        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              const batchData = mockResults.slice(start, end + 1);
              callback({ data: batchData, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'layer2', {
            status: 'approved',
            confidence: 'high',
          });

          let csvContent = '';
          for await (const chunk of stream) {
            csvContent += chunk.toString();
          }

          const lines = csvContent.split('\n').filter(line => line.trim().length > 0);
          const headerLine = lines[0];
          const columnCount = countCSVColumns(headerLine);

          // Assert - Column structure unchanged by filters
          expect(columnCount).toBeGreaterThanOrEqual(20);
          expect(columnCount).toBeLessThanOrEqual(25);

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });
    });

    describe('Cascade Handling Tests', () => {
      it('should handle summary format for all elimination scenarios', async () => {
        // Arrange - Mix of all elimination scenarios
        const mockResults: UrlResult[] = [
          { ...generateMockUrlResult(0), eliminated_at_layer: 'layer1' },
          { ...generateMockUrlResult(1), eliminated_at_layer: 'layer2' },
          { ...generateMockUrlResult(2), eliminated_at_layer: 'layer3' },
          { ...generateMockUrlResult(3), eliminated_at_layer: 'passed_all' },
        ];

        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              callback({ data: mockResults, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'summary');

          let csvContent = '';
          for await (const chunk of stream) {
            csvContent += chunk.toString();
          }

          const lines = csvContent.split('\n').filter(line => line.trim().length > 0);

          // Assert - All rows should have summary data regardless of elimination layer
          expect(lines.length).toBe(5); // 1 header + 4 data rows

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });

      it('should show Layer2 data only for URLs that passed Layer1', async () => {
        // Arrange - URLs eliminated at different layers
        const mockResults: UrlResult[] = [
          {
            ...generateMockUrlResult(0),
            eliminated_at_layer: 'layer1',
            layer2_factors: null, // No Layer 2 data
          },
          {
            ...generateMockUrlResult(1),
            eliminated_at_layer: 'layer2',
            layer2_factors: { /* Has Layer 2 data */ } as any,
          },
          {
            ...generateMockUrlResult(2),
            eliminated_at_layer: 'passed_all',
            layer2_factors: { /* Has Layer 2 data */ } as any,
          },
        ];

        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              callback({ data: mockResults, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'layer2');

          let csvContent = '';
          for await (const chunk of stream) {
            csvContent += chunk.toString();
          }

          // Assert - Layer2 format should handle null layer2_factors gracefully
          expect(csvContent).toBeTruthy();

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });

      it('should show Layer3 data only for URLs that reached Layer3', async () => {
        // Arrange
        const mockResults: UrlResult[] = [
          {
            ...generateMockUrlResult(0),
            eliminated_at_layer: 'layer1',
            layer3_factors: null,
          },
          {
            ...generateMockUrlResult(1),
            eliminated_at_layer: 'layer2',
            layer3_factors: null,
          },
          {
            ...generateMockUrlResult(2),
            eliminated_at_layer: 'layer3',
            layer3_factors: { /* Has Layer 3 data */ } as any,
          },
          {
            ...generateMockUrlResult(3),
            eliminated_at_layer: 'passed_all',
            layer3_factors: { /* Has Layer 3 data */ } as any,
          },
        ];

        mockSupabaseClient.range.mockImplementation((start: number, end: number) => {
          return {
            then: (callback: (result: { data: UrlResult[]; error: null }) => void) => {
              callback({ data: mockResults, error: null });
            },
          };
        });

        // Act
        try {
          const stream = await exportService.streamCSVExport('test-job-id', 'layer3');

          let csvContent = '';
          for await (const chunk of stream) {
            csvContent += chunk.toString();
          }

          // Assert - Layer3 format should handle null layer3_factors gracefully
          expect(csvContent).toBeTruthy();

        } catch (error) {
          expect((error as Error).message).toBe('Not implemented yet - TDD approach');
        }
      });
    });
  });
});

/**
 * CSV Escaping Tests (T059)
 * Task T059 [Phase 5 - User Story 3]
 *
 * Comprehensive tests for RFC 4180 CSV escaping rules.
 *
 * RFC 4180 Escaping Rules:
 * 1. Comma (,) in value -> Wrap in quotes
 * 2. Double quote (") in value -> Escape with "" + wrap in quotes
 * 3. Newline (\n) in value -> Wrap in quotes
 * 4. Carriage return (\r) in value -> Wrap in quotes
 * 5. Tab and other chars -> No escaping unless contains comma/newline/quote
 * 6. Excel Compatibility -> UTF-8 BOM + CRLF line endings
 *
 * Test Coverage:
 * - 22 total tests covering all RFC 4180 rules
 * - Basic escaping (comma, quote, newline, multiple special chars)
 * - Edge cases (single quote, tab, only comma, only newline)
 * - Multi-column scenarios (mixed escaping needs)
 * - Real data scenarios (pattern lists, reasoning fields, signals)
 * - Excel compatibility (UTF-8 BOM, CRLF, normalization)
 * - Performance (large fields, many special chars)
 * - NULL/undefined/empty value handling
 * - Special character edge cases
 */
describe('ExportService - CSV Escaping Tests (T059)', () => {
  let exportService: ExportService;
  let mockSupabaseService: MockSupabaseService;

  beforeAll(async () => {
    mockSupabaseService = new MockSupabaseService();

    const moduleFixture: TestingModule = await Test.createTestingModule({
      providers: [
        ExportService,
        {
          provide: SupabaseService,
          useValue: mockSupabaseService,
        },
      ],
    }).compile();

    exportService = moduleFixture.get<ExportService>(ExportService);
  });

  describe('1. Basic Escaping Tests', () => {
    it('Test 1: should escape URL with comma by wrapping in quotes', () => {
      // RFC 4180 Rule 1: Comma triggers quoting
      const input = 'example.com, with comma';
      const expected = '"example.com, with comma"';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        // Expected to fail during TDD phase
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('Test 2: should escape reasoning with double quotes by doubling them', () => {
      // RFC 4180 Rule 2: Double quotes must be escaped with ""
      const input = 'Domain is "commercial"';
      const expected = '"Domain is ""commercial"""';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('Test 3: should escape reasoning with embedded newline by wrapping in quotes', () => {
      // RFC 4180 Rule 3: Newline triggers quoting (literal newline preserved)
      const input = 'Line 1\nLine 2\nLine 3';
      const expected = '"Line 1\nLine 2\nLine 3"';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('Test 4: should handle multiple special chars in single field', () => {
      // RFC 4180 Combined Rules: Multiple special chars require escaping
      const input = '"quoted, value"\nwith newline';
      const expected = '"""quoted, value""\nwith newline"';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });
  });

  describe('2. Escaping Edge Cases', () => {
    it('Test 5: should NOT escape single quote (no escaping needed)', () => {
      // RFC 4180: Single quotes don't need escaping
      const input = "apostrophe's test";
      const expected = "apostrophe's test";

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('Test 6: should NOT escape tab character alone', () => {
      // RFC 4180: Tabs alone don't trigger quoting
      const input = 'col1\tcol2';
      const expected = 'col1\tcol2';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('Test 7: should escape only when comma is present', () => {
      // RFC 4180: Only comma triggers quoting
      const input = 'a,b';
      const expected = '"a,b"';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('Test 8: should escape only when newline is present', () => {
      // RFC 4180: Only newline triggers quoting
      const input = 'line\nmore';
      const expected = '"line\nmore"';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });
  });

  describe('3. Complex Multi-column Tests', () => {
    it('Test 9: should handle multiple fields with different escape needs', () => {
      // RFC 4180: Row with mixed escaping requirements
      const inputRow = ['simple', 'with,comma', 'with"quote', 'with\nnewline'];
      const expected = 'simple,"with,comma","with""quote","with\nnewline"';

      try {
        const result = exportService.formatCSVRow(inputRow);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('Test 10: should handle all columns needing escaping', () => {
      // RFC 4180: All fields require escaping
      const inputRow = [
        'field,with,commas',
        'field"with"quotes',
        'field\nwith\nnewlines',
        'field with "quotes, commas" and\nnewlines',
      ];
      const expected =
        '"field,with,commas","field""with""quotes","field\nwith\nnewlines","field with ""quotes, commas"" and\nnewlines"';

      try {
        const result = exportService.formatCSVRow(inputRow);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });
  });

  describe('4. Real Data Scenarios', () => {
    it('Test 11: should escape pattern matches field (multi-value comma-separated)', () => {
      // Real-world scenario: Layer 1 pattern_matches field
      const input = 'pattern1, pattern2, pattern3';
      const expected = '"pattern1, pattern2, pattern3"';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('Test 12: should escape reasoning field with multiple sentences', () => {
      // Real-world scenario: Layer 1/2/3 reasoning field with newlines
      const input = 'First sentence. Second sentence.\nThird sentence on new line.';
      const expected = '"First sentence. Second sentence.\nThird sentence on new line."';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('Test 13: should escape signal list (multi-value field)', () => {
      // Real-world scenario: Layer 3 sophistication signals with quotes and commas
      const input = 'signal1, signal2, "quoted signal", signal3';
      const expected = '"signal1, signal2, ""quoted signal"", signal3"';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });
  });

  describe('5. Excel Compatibility Tests', () => {
    it('Test 14: should include UTF-8 BOM (0xEF 0xBB 0xBF) at start of CSV', () => {
      // RFC 4180 + Excel: UTF-8 BOM for proper Excel encoding
      const rows = ['Header1,Header2', 'Value1,Value2'];
      const BOM = '\uFEFF';

      try {
        const result = exportService.generateCSVWithBOM(rows);

        // Check BOM presence
        expect(result.charCodeAt(0)).toBe(0xfeff);
        expect(result.startsWith(BOM)).toBe(true);

        // Check content follows BOM
        expect(result.substring(1)).toContain('Header1,Header2');
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('Test 15: should use CRLF line endings (not LF)', () => {
      // RFC 4180: CRLF (\r\n) line endings for Excel compatibility
      const rows = ['Header1,Header2', 'Value1,Value2', 'Value3,Value4'];

      try {
        const result = exportService.generateCSVWithBOM(rows);

        // Strip BOM for line ending check
        const withoutBOM = result.substring(1);

        // Verify CRLF line endings
        expect(withoutBOM).toContain('\r\n');
        expect(withoutBOM).not.toMatch(/(?<!\r)\n/); // No LF without CR

        // Count CRLF occurrences (should be 2 for 3 rows)
        const crlfCount = (withoutBOM.match(/\r\n/g) || []).length;
        expect(crlfCount).toBeGreaterThanOrEqual(2);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('Test 16: should normalize mixed LF/CRLF to consistent CRLF', () => {
      // RFC 4180: Normalize mixed line endings to CRLF
      const rows = ['Header1,Header2', 'Value with\nmixed\r\nline endings', 'Value3,Value4'];

      try {
        const result = exportService.generateCSVWithBOM(rows);

        // Check that content uses CRLF for row separators
        const withoutBOM = result.substring(1);
        const lines = withoutBOM.split('\r\n');

        expect(lines.length).toBeGreaterThan(1);

        // Verify field with embedded newline is properly quoted
        const secondLine = lines[1];
        expect(secondLine).toContain('"');
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });
  });

  describe('6. Performance Escaping Tests', () => {
    it('Test 17: should handle large field (10KB reasoning) without failure', () => {
      // Performance: Large text field with special characters
      const largeText = 'Line with "quotes", commas, and\nnewlines. '.repeat(300); // ~10KB
      const estimatedSize = largeText.length;

      expect(estimatedSize).toBeGreaterThan(10000); // Verify > 10KB

      try {
        const startTime = Date.now();
        const result = exportService.escapeCSVField(largeText);
        const elapsedTime = Date.now() - startTime;

        // Should complete quickly (< 100ms)
        expect(elapsedTime).toBeLessThan(100);

        // Should be properly escaped
        expect(result.startsWith('"')).toBe(true);
        expect(result.endsWith('"')).toBe(true);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('Test 18: should handle field with many special characters efficiently', () => {
      // Performance: Field with 100+ special character combinations
      let complexField = '';
      for (let i = 0; i < 100; i++) {
        complexField += `text${i}, "quoted${i}"\n`;
      }

      try {
        const startTime = Date.now();
        const result = exportService.escapeCSVField(complexField);
        const elapsedTime = Date.now() - startTime;

        // Should complete quickly (< 50ms)
        expect(elapsedTime).toBeLessThan(50);

        // Verify correct escaping maintained
        expect(result.startsWith('"')).toBe(true);
        expect(result.endsWith('"')).toBe(true);

        // Count escaped quotes (should have doubled quotes)
        const originalQuoteCount = (complexField.match(/"/g) || []).length;
        const escapedQuoteCount = (result.match(/"/g) || []).length;

        // Result should have more quotes (original doubled + 2 wrapper quotes)
        expect(escapedQuoteCount).toBeGreaterThan(originalQuoteCount);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });
  });

  describe('7. NULL and Empty Value Handling', () => {
    it('should handle NULL values by returning empty string', () => {
      // RFC 4180: NULL values should be represented as empty fields
      const input = null;
      const expected = '';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('should handle undefined values by returning empty string', () => {
      // RFC 4180: Undefined values should be represented as empty fields
      const input = undefined;
      const expected = '';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('should handle empty string without adding quotes', () => {
      // RFC 4180: Empty strings don't need quotes unless forced
      const input = '';
      const expected = '';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('should handle row with mixed NULL, undefined, and empty values', () => {
      // Real-world scenario: Row with missing data
      const inputRow = ['value1', null, undefined, '', 'value5'];
      const expected = 'value1,,,,value5';

      try {
        const result = exportService.formatCSVRow(inputRow);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });
  });

  describe('8. Special Character Edge Cases', () => {
    it('should handle field with only double quotes', () => {
      const input = '"""';
      const expected = '"""""""'; // Each quote doubled + wrapper quotes

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('should handle field with only commas', () => {
      const input = ',,,';
      const expected = '",,,,"';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('should handle CRLF sequences in field content', () => {
      // RFC 4180 Rule 4: CRLF in field content should be preserved
      const input = 'line1\r\nline2\r\nline3';
      const expected = '"line1\r\nline2\r\nline3"';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('should handle Unicode characters without corruption', () => {
      // RFC 4180 + UTF-8: Unicode should be preserved
      const input = 'Text with mojis  and spcial chracters';
      const expected = 'Text with mojis  and spcial chracters';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });

    it('should handle field with leading/trailing whitespace', () => {
      // RFC 4180: Whitespace should be preserved
      const input = '  leading and trailing  ';
      const expected = '  leading and trailing  ';

      try {
        const result = exportService.escapeCSVField(input);
        expect(result).toBe(expected);
      } catch (error) {
        expect((error as Error).message).toBe('Not implemented yet - TDD approach');
      }
    });
  });
});
