<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>2.5-refactored</storyId>
    <title>3-Tier Pipeline Orchestration &amp; Real-Time Updates (REFACTORED)</title>
    <status>Draft</status>
    <generatedAt>2025-10-16</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/docs/stories/story-2.5-refactored.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>system</asA>
    <iWant>orchestrate the 3-tier progressive filtering pipeline (Layer 1 → Layer 2 → Layer 3) with real-time updates</iWant>
    <soThat>URLs are efficiently filtered at each layer with transparency and cost optimization</soThat>
    <tasks>
      Task 1: Refactor Worker Pipeline for 3-Tier Architecture
      Task 2: Layer 1 Integration
      Task 3: Layer 2 Integration
      Task 4: Layer 3 Integration
      Task 5: Current Layer Tracking
      Task 6: Cost Tracking and Savings Calculation
      Task 7: Worker Concurrency Optimization
      Task 8: Error Handling Per Layer
      Task 9: Job Controls Integration
      Task 10: Metrics Aggregation
      Task 11: Database Schema Updates
      Task 12: Unit Testing
      Task 13: Integration Testing
    </tasks>
  </story>

  <acceptanceCriteria>
    AC1: Layer 1 Integration (Domain Analysis - NO HTTP) - Layer1DomainAnalysisService integrated, domain patterns checked before HTTP, elimination persisted, counter updated, target 40-60% elimination
    AC2: Layer 2 Integration (Homepage Scraping + Operational Validation) - Called only if Layer 1 PASS, homepage-only scraping, company/blog/tech detection, signals stored in JSONB, target 30% elimination of Layer 1 survivors
    AC3: Layer 3 Integration (LLM Classification with Confidence Scoring) - Called only if Layer 2 PASS, full site scraping, Gemini primary/GPT fallback, confidence bands, manual review routing, target 10-15 URLs/min
    AC4: Pipeline Orchestration Flow - Sequential layer processing with STOP on elimination, current_layer tracking, per-layer timing, job-level metrics aggregation
    AC5: Real-Time Database Updates (Supabase Realtime) - Database triggers Realtime events, job status lifecycle, current layer tracking, result inserts, activity logging, &lt;500ms latency
    AC6: Cost Tracking Per Layer - Layer 1: $0, Layer 2: ~$0.0001/URL, Layer 3: ~$0.002-0.004/URL, estimated savings calculation
    AC7: Worker Concurrency and Rate Limiting - BullMQ 5 concurrent workers, Layer 1: 100+ URLs/min, Layer 2: 20-30 URLs/min, Layer 3: 10-15 URLs/min, overall 20+ URLs/min
    AC8: Error Handling Per Layer - Layer 1 fail-open, Layer 2/3 retry with backoff, isolated error handling, ScrapingBee 429 handling
    AC9: Job Controls (Pause/Resume/Cancel) - Pause/resume checks status before processing, cancel preserves results, graceful shutdown finishes current layer
    AC10: Metrics and Reporting - Job-level aggregates, per-layer pass rates, cost breakdown, processing efficiency, real-time progress tracking
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc path="/docs/PRD.md" section="FR008" title="3-Tier Progressive Filtering">
        Layer 1 (domain analysis), Layer 2 (homepage scraping + operational validation), Layer 3 (LLM classification). Target: 40-60% Layer 1 elimination, 30% Layer 2 elimination, final LLM classification on 28% of URLs.
      </doc>
      <doc path="/docs/PRD.md" section="NFR002" title="Performance Requirements">
        Layer 1: 100+ URLs/min, Layer 2: 20-30 URLs/min, Layer 3: 10-15 URLs/min. Overall pipeline: 20+ URLs/min.
      </doc>
      <doc path="/docs/PRD.md" section="NFR003" title="Cost Optimization">
        Target 60-70% LLM cost savings + 40-60% scraping cost savings via progressive filtering. Cost tracking per layer.
      </doc>
      <doc path="/docs/tech-spec-epic-2.md" section="Story 2.5 (lines 411-422)" title="Worker Processing Requirements">
        BullMQ worker with concurrency 5, real-time Supabase updates, pause/resume support, graceful shutdown, error isolation.
      </doc>
      <doc path="/docs/sprint-change-proposal-3tier-architecture-2025-10-16.md" section="Architecture Refactor" title="3-Tier Architecture Rationale">
        Fundamental misalignment resolved: scraping → filtering → LLM changed to filtering → scraping → LLM for cost efficiency and better qualification.
      </doc>
      <doc path="/docs/stories/story-2.3-refactored.md" title="Layer 1 Domain Analysis">
        Layer1DomainAnalysisService: NO HTTP requests, domain pattern matching, TLD filtering, target 40-60% elimination.
      </doc>
      <doc path="/docs/stories/story-2.4-refactored.md" title="Layer 3 LLM Classification">
        ClassificationService with confidence scoring, ConfidenceScoringService for bands (high/medium/low/auto_reject), ManualReviewRouterService for medium/low confidence.
      </doc>
      <doc path="/docs/stories/story-2.5.md" title="Original Worker Processing">
        ScraperService, BullMQ worker setup, graceful shutdown, retry logic, real-time updates implemented in Story 2.5.
      </doc>
    </docs>
    <code>
      <file path="apps/api/src/workers/url-worker.processor.ts" lines="1-100" reason="Current worker implementation with Layer 1 integration (Story 2.3), needs refactor for full 3-tier orchestration">
        Processor decorator with concurrency 5, Layer1DomainAnalysisService already integrated, ScraperService, PreFilterService, LlmService, ConfidenceScoringService, ManualReviewRouterService injected.
      </file>
      <file path="apps/api/src/workers/url-worker.processor.ts" lines="78-96" reason="Layer 1 integration example - shows STOP logic on elimination">
        Layer 1 domain analysis called first, if rejected stores elimination and returns early (STOP). Pattern to replicate for Layer 2.
      </file>
      <file path="apps/api/src/jobs/services/layer1-domain-analysis.service.ts" reason="Layer 1 service implementation to call in worker pipeline">
        analyzeUrl() method returns {passed, reasoning, processingTimeMs}. NO HTTP requests, instant domain checks.
      </file>
      <file path="apps/api/src/jobs/services/confidence-scoring.service.ts" reason="Layer 3 confidence scoring service">
        calculateConfidenceBand() method, uses configurable thresholds from database.
      </file>
      <file path="apps/api/src/jobs/services/manual-review-router.service.ts" reason="Layer 3 manual review routing service">
        shouldRouteToManualReview() method for medium/low confidence URLs.
      </file>
      <file path="apps/api/src/scraper/scraper.service.ts" reason="ScrapingBee integration - needs fullSite flag added for Layer 2 vs Layer 3 differentiation">
        fetchUrl() method for scraping, needs fullSite parameter: false for Layer 2 (homepage only), true for Layer 3 (full site).
      </file>
      <file path="apps/api/src/jobs/services/llm.service.ts" reason="LLM classification service (Layer 3)">
        classifyUrl() method with Gemini primary, GPT fallback. Returns {classification, confidence, reasoning, provider, cost}.
      </file>
    </code>
    <dependencies>
      <node>
        <package name="@nestjs/bullmq" version="^10.1.0" purpose="BullMQ worker processor integration"/>
        <package name="bullmq" version="^5.0.0" purpose="Queue system for URL processing"/>
        <package name="@supabase/supabase-js" version="^2.39.0" purpose="Database and Realtime updates"/>
        <package name="cheerio" version="^1.1.2" purpose="HTML parsing for content extraction"/>
        <package name="axios" version="^1.12.2" purpose="HTTP client for ScrapingBee, Gemini, GPT APIs"/>
        <package name="@google/generative-ai" version="^0.24.1" purpose="Gemini API client"/>
        <package name="openai" version="^6.3.0" purpose="GPT API client"/>
        <package name="zod" version="^3.25.76" purpose="Schema validation"/>
        <package name="class-validator" version="^0.14.2" purpose="DTO validation"/>
      </node>
    </dependencies>
  </artifacts>

  <constraints>
    1. CRITICAL: Layer 1 MUST execute BEFORE any HTTP requests (domain analysis only)
    2. CRITICAL: Layer 2 MUST use homepage-only scraping (NOT full site) for operational validation
    3. CRITICAL: Layer 3 MUST use full site scraping for comprehensive LLM classification
    4. CRITICAL: STOP processing immediately on elimination at any layer (don't proceed to next layer)
    5. Service Registration: All new services MUST be registered in WorkersModule providers AND exports arrays
    6. Database Migration: MUST create and apply migration for current_layer, scraping_cost, estimated_savings, layer timing fields
    7. Fail-Open Strategy: Layer 1 errors LOG WARNING and continue to Layer 2 (safety fallback)
    8. Graceful Shutdown: Already implemented via worker.close() in onModuleDestroy() - verify still works after refactor
    9. Atomic Counters: Use RPC functions for layer elimination counters to prevent race conditions with concurrent workers
    10. Real-Time Updates: Supabase Realtime automatic on database updates - no manual triggers needed
    11. Cost Tracking: Calculate estimated_savings = (layer1_eliminated × layer2_cost) + ((layer1_eliminated + layer2_eliminated) × layer3_cost)
    12. Retry Logic: Layer 2/3 scraping errors retry 3 times with exponential backoff, Layer 1 NO retry (instant)
  </constraints>

  <interfaces>
    <interface name="Layer1DomainAnalysisService.analyzeUrl()" signature="analyzeUrl(url: string): {passed: boolean, reasoning: string, processingTimeMs: number}" path="apps/api/src/jobs/services/layer1-domain-analysis.service.ts">
      NO HTTP requests, instant domain pattern checks, returns elimination reasoning
    </interface>
    <interface name="Layer2OperationalFilterService.validateOperational()" signature="validateOperational(url: string, homepageContent: ScraperResult): {passed: boolean, reasoning: string, signals: object}" path="apps/api/src/jobs/services/layer2-operational-filter.service.ts (PENDING Story 2.6)">
      Analyzes homepage-only content for company pages, blog freshness, tech stack. Returns signals in JSONB format.
    </interface>
    <interface name="ScraperService.fetchUrl()" signature="fetchUrl(url: string, options?: {fullSite: boolean}): Promise&lt;ScraperResult&gt;" path="apps/api/src/scraper/scraper.service.ts">
      NEEDS MODIFICATION: Add fullSite flag. False = homepage only (Layer 2), True = full site (Layer 3).
    </interface>
    <interface name="ClassificationService.classifyUrl()" signature="classifyUrl(url: string, content: string): Promise&lt;{classification, confidence, reasoning, provider, cost}&gt;" path="apps/api/src/jobs/services/llm.service.ts">
      Gemini primary, GPT fallback. Returns confidence score 0-1 for band calculation.
    </interface>
    <interface name="ConfidenceScoringService.calculateConfidenceBand()" signature="calculateConfidenceBand(confidence: number, signals: string[]): Promise&lt;string&gt;" path="apps/api/src/jobs/services/confidence-scoring.service.ts">
      Returns 'high' (0.8+), 'medium' (0.5-0.79), 'low' (0.3-0.49), or 'auto_reject' (&lt;0.3)
    </interface>
    <interface name="ManualReviewRouterService.shouldRouteToManualReview()" signature="shouldRouteToManualReview(confidenceBand: string, confidence: number, url: string): boolean" path="apps/api/src/jobs/services/manual-review-router.service.ts">
      Returns true for 'medium' or 'low' confidence bands. Logs routing decisions.
    </interface>
    <interface name="Supabase RPC increment_job_counters()" signature="increment_job_counters(p_job_id, p_layer1_eliminated_delta?, p_layer2_eliminated_delta?, ...)" path="Supabase database function">
      Atomic counter updates to prevent race conditions. Supports layer1_eliminated_count, layer2_eliminated_count, processed_urls, etc.
    </interface>
  </interfaces>

  <tests>
    <standards>
      Jest testing framework. Unit tests with >85% coverage target. Integration tests for full pipeline flow. Mock external APIs (ScrapingBee, Gemini, GPT) with nock or service test doubles. Real Supabase test database for Realtime integration tests. Performance tests: Layer 1 (100+ URLs/min), Layer 2 (20-30 URLs/min), Layer 3 (10-15 URLs/min), overall (20+ URLs/min).
    </standards>
    <locations>
      apps/api/src/workers/__tests__/url-worker.processor.spec.ts
      apps/api/src/workers/__tests__/integration/realtime.integration.spec.ts
      apps/api/src/jobs/__tests__/layer1-domain-analysis.service.spec.ts
      apps/api/src/jobs/__tests__/confidence-scoring.service.spec.ts
      apps/api/src/jobs/__tests__/manual-review-router.service.spec.ts
    </locations>
    <ideas>
      <test ac="AC1" idea="Unit test: Layer 1 REJECT flow - verify elimination persisted, Layer 2/3 not called, layer1_eliminated_count incremented"/>
      <test ac="AC2" idea="Unit test: Layer 1 PASS → Layer 2 REJECT flow - verify Layer 3 not called, layer2_eliminated_count incremented"/>
      <test ac="AC3" idea="Unit test: Layer 2 PASS → Layer 3 flow - verify full pipeline executes, confidence_band stored, manual review routing"/>
      <test ac="AC4" idea="Unit test: current_layer tracking - verify updates to 1, 2, 3 during processing"/>
      <test ac="AC5" idea="Integration test: Supabase Realtime events - verify job/result updates trigger Realtime broadcasts"/>
      <test ac="AC6" idea="Unit test: Cost savings calculation - verify formula (layer1_eliminated × layer2_cost) + ((layer1_eliminated + layer2_eliminated) × layer3_cost)"/>
      <test ac="AC7" idea="Integration test: Worker concurrency - verify 5 concurrent URLs respect ScrapingBee rate limits"/>
      <test ac="AC8" idea="Unit test: Error handling - Layer 1 fail-open (log warning, continue), Layer 2/3 retry with backoff"/>
      <test ac="AC9" idea="Integration test: Pause/resume - verify pause stops after current layer completes, resume continues from last URL"/>
      <test ac="AC10" idea="Unit test: Metrics aggregation - verify layer counters, pass rates, cost breakdown calculated correctly"/>
      <test ac="ALL" idea="E2E integration test: 100 URLs → Layer 1 eliminates 50 → Layer 2 eliminates 15 → Layer 3 classifies 35, verify all metrics"/>
    </ideas>
  </tests>
</story-context>
