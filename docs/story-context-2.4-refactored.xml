<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>2.4-refactored</storyId>
    <title>Layer 3 - LLM Classification with Confidence Scoring (REFACTORED)</title>
    <status>Draft</status>
    <generatedAt>2025-10-16</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/docs/stories/story-2.4-refactored.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>a system</asA>
    <iWant>to classify URLs using Gemini primary and GPT fallback with confidence-based routing</iWant>
    <soThat>we get reliable classifications at lowest cost and route uncertain results to manual review</soThat>

    <tasks>
      <task id="1" ac="1,3">Refactor Existing LLM Service for Confidence Scoring</task>
      <task id="2" ac="2">Enhance Classification Prompt</task>
      <task id="3" ac="3,4">Create Confidence Scoring Service</task>
      <task id="4" ac="5">Create Manual Review Router Service</task>
      <task id="5" ac="6,7">Update Database Schema</task>
      <task id="6" ac="6">Update Shared Types</task>
      <task id="7" ac="8">Configuration Integration</task>
      <task id="8" ac="9">Worker Pipeline Integration</task>
      <task id="9" ac="ALL">Unit Testing</task>
      <task id="10" ac="9,10">Integration Testing</task>
      <task id="11" ac="ALL">Address Lessons Learned from Story 2.4</task>
    </tasks>
  </story>

  <acceptanceCriteria>
    <ac id="AC1" title="LLM Service Configuration">
      <criteria>LLM service configured with Gemini 2.0 Flash API (primary)</criteria>
      <criteria>OpenAI GPT-4o-mini API configured (fallback)</criteria>
      <criteria>Gemini API called first for each URL</criteria>
      <criteria>GPT fallback triggered on: Gemini API error, timeout (&gt;30s), rate limit</criteria>
      <criteria>Fallback logged: "GPT fallback used - Gemini timeout"</criteria>
      <criteria>Retry logic: 3 attempts with exponential backoff (1s, 2s, 4s) for transient errors</criteria>
      <criteria>Permanent failures marked: status "failed", error message stored</criteria>
    </ac>

    <ac id="AC2" title="Enhanced Classification Prompt">
      <criteria>Classification prompt includes content marketing sophistication indicators</criteria>
      <criteria>SEO investment signal detection</criteria>
      <criteria>Guest post opportunity signals</criteria>
      <criteria>More nuanced reasoning for confidence scoring</criteria>
      <criteria>Prompt requests JSON response: {suitable: boolean, confidence: 0-1, reasoning: string, sophistication_signals: array}</criteria>
    </ac>

    <ac id="AC3" title="Confidence Scoring">
      <criteria>Classification response includes confidence field (0-1 scale)</criteria>
      <criteria>Confidence reflects LLM certainty in classification decision</criteria>
      <criteria>Confidence scoring considers: signal strength, content clarity, consistency across indicators</criteria>
    </ac>

    <ac id="AC4" title="Confidence Bands">
      <criteria>High confidence (0.8-1.0): Auto-approve as "suitable"</criteria>
      <criteria>Medium confidence (0.5-0.79): Route to manual review queue</criteria>
      <criteria>Low confidence (0.3-0.49): Route to manual review queue</criteria>
      <criteria>Auto-reject (0-0.29): Mark as "not_suitable"</criteria>
      <criteria>Store confidence_band field (high/medium/low/auto_reject) in database</criteria>
    </ac>

    <ac id="AC5" title="Manual Review Queue Routing">
      <criteria>Create ManualReviewRouterService in apps/api/src/jobs/services/</criteria>
      <criteria>Mark manual_review_required = true for medium/low confidence results</criteria>
      <criteria>Track manual review queue size in job metrics</criteria>
      <criteria>Log routing decisions: "Medium confidence (0.65) - Routed to manual review"</criteria>
      <criteria>Queue entries persist in database with URL, confidence score, reasoning</criteria>
    </ac>

    <ac id="AC6" title="Result Storage">
      <criteria>Classification result stored with ALL fields: classification, classification_score, confidence_band, classification_reasoning, llm_provider, manual_review_required, llm_cost, processing_time_ms</criteria>
      <criteria>Cost calculated per URL based on token usage</criteria>
      <criteria>Processing time tracked per URL</criteria>
    </ac>

    <ac id="AC7" title="Database Integration">
      <criteria>Database migration created for NEW fields: confidence_band VARCHAR, manual_review_required BOOLEAN</criteria>
      <criteria>Migration applied to Supabase (verified via Supabase MCP)</criteria>
      <criteria>Existing LLM fields retained: classification_score, classification_reasoning, llm_provider, llm_cost</criteria>
    </ac>

    <ac id="AC8" title="Configuration Integration (Story 3.0)">
      <criteria>Load Layer 3 rules from classification_settings.layer3_rules (database)</criteria>
      <criteria>Fallback to default configuration if database unavailable</criteria>
      <criteria>Configurable parameters: LLM temperature, content truncation limit, confidence band thresholds, classification indicators</criteria>
    </ac>

    <ac id="AC9" title="Integration with Worker Pipeline">
      <criteria>Layer 3 service called ONLY after Layer 2 PASS</criteria>
      <criteria>Worker integration in url-worker.processor.ts</criteria>
      <criteria>Processing flow: Layer 2 PASS → Full site scraping → Layer 3 classification</criteria>
      <criteria>Layer 3 results update current_layer = 3 in jobs table</criteria>
      <criteria>Real-time updates via Supabase Realtime</criteria>
    </ac>

    <ac id="AC10" title="Performance and Cost Targets">
      <criteria>Processing rate: 10-15 URLs/minute (Layer 3 processing)</criteria>
      <criteria>LLM API latency: &lt;10 seconds per URL (including retries)</criteria>
      <criteria>Cost tracking accurate: Gemini vs GPT costs separated</criteria>
      <criteria>Manual review routing: 35% of Layer 2 survivors (medium/low confidence)</criteria>
    </ac>
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <artifact>
        <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>FR008: Intelligent Progressive Filtering</section>
        <snippet>System shall apply 3-tier progressive filtering: (1) Domain/URL pattern analysis without HTTP requests to eliminate 40-60% of candidates, (2) Homepage scraping and company validation to eliminate additional 20-30%, (3) LLM classification with confidence-based routing to manual review queue. All filtering decisions visible in logs with per-layer elimination reasoning.</snippet>
        <relevance>Defines 3-tier architecture and Layer 3 confidence-based routing requirement</relevance>
      </artifact>

      <artifact>
        <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>FR009: AI-Powered Classification</section>
        <snippet>System shall classify each URL for guest posting suitability using Gemini 2.0 Flash as primary LLM with automatic fallback to GPT-4o-mini on failures, with classification reasoning logged.</snippet>
        <relevance>Defines LLM classification requirement with Gemini/GPT fallback</relevance>
      </artifact>

      <artifact>
        <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>Layer 3 Tracking Fields</section>
        <snippet>confidence_band (VARCHAR) - Stores confidence classification (high/medium/low/auto_reject); manual_review_required (BOOLEAN) - Flags medium/low confidence for manual review; current_layer (INTEGER) - Tracks current processing layer (1/2/3) for real-time dashboard</snippet>
        <relevance>Specifies exact database schema fields for Layer 3 confidence tracking</relevance>
      </artifact>

      <artifact>
        <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/docs/tech-spec-epic-2.md</path>
        <title>Technical Specification: Production-Grade Processing Pipeline</title>
        <section>Story 2.4: LLM Classification</section>
        <snippet>AC2.4.1: LLM service configured with Gemini 2.0 Flash (primary) and GPT-4o-mini (fallback); AC2.4.3: Gemini API called first for each URL; AC2.4.4: GPT fallback triggered on: Gemini API error, timeout (&gt;30s), rate limit; AC2.4.8: Retry logic: 3 attempts with exponential backoff (1s, 2s, 4s) for transient errors</snippet>
        <relevance>Authoritative acceptance criteria from original Story 2.4 (still applicable to refactored version)</relevance>
      </artifact>

      <artifact>
        <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/docs/stories/story-2.4-refactored.md</path>
        <title>Story 2.4 Refactored</title>
        <section>Dev Notes - Refactoring Overview</section>
        <snippet>Key Changes from Original Story 2.4: 1. Service Rename: LlmService → ClassificationService (Layer 3 orchestrator); 2. New Services: ConfidenceScoringService, ManualReviewRouterService; 3. Enhanced Prompt: Added sophistication signals and SEO investment indicators; 4. Confidence Bands: 4-tier classification (high/medium/low/auto_reject); 5. Manual Review Queue: Medium/low confidence results routed for human validation</snippet>
        <relevance>Defines key architectural changes in refactored implementation</relevance>
      </artifact>

      <artifact>
        <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/docs/stories/story-2.4-refactored.md</path>
        <title>Story 2.4 Refactored</title>
        <section>Dev Notes - Enhanced Classification Prompt Structure</section>
        <snippet>Content Marketing Sophistication Indicators: Author bylines with external contributor profiles, Editorial quality, Audience engagement signals; SEO Investment Signals: Structured data (schema markup, JSON-LD), Meta optimization, Technical SEO; Guest Post Opportunity Signals: Explicit "Write for Us" pages, Contributor sections, Submission forms</snippet>
        <relevance>Defines enhanced prompt structure with sophistication indicators for confidence scoring</relevance>
      </artifact>

      <artifact>
        <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/docs/stories/story-2.4-refactored.md</path>
        <title>Story 2.4 Refactored</title>
        <section>Dev Notes - Lessons Learned from Story 2.4 (Applied)</section>
        <snippet>1. Complete Skipped Test Suite (AI-Review-M1) - FIXED: All unit tests will be implemented (no describe.skip blocks); 2. Create Database Migration (AI-Review-M2) - FIXED: Migration file created AND applied via Supabase MCP; 3. Externalize Configuration Constants (AI-Review-M3) - FIXED: Load from classification_settings.layer3_rules (Story 3.0)</snippet>
        <relevance>Critical lessons learned from original Story 2.4 implementation that MUST be applied</relevance>
      </artifact>

      <artifact>
        <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/docs/stories/story-2.3-refactored.md</path>
        <title>Story 2.3 Refactored - Layer 1 Domain Analysis</title>
        <section>Senior Developer Review - Critical Integration Patterns</section>
        <snippet>1. Service Registration in JobsModule - CRITICAL: Add all services to providers AND exports arrays; 2. Worker Pipeline Integration - CRITICAL: Update url-worker.processor.ts to call Layer 3 after Layer 2 PASS; 3. Database Migration Application - CRITICAL: Run migration via Supabase MCP, verify with SELECT query; 4. Configuration File Path Resolution - CRITICAL: Load from database (Story 3.0), not file system</snippet>
        <relevance>Critical integration patterns from Story 2.3-refactored that apply to Story 2.4-refactored</relevance>
      </artifact>
    </docs>

    <code>
      <artifact>
        <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/apps/api/src/jobs/services/llm.service.ts</path>
        <kind>service</kind>
        <symbol>LlmService</symbol>
        <lines>1-523</lines>
        <reason>Existing LLM service implementation from original Story 2.4 - provides Gemini/GPT fallback logic, retry handling, and cost calculation that should be refactored into ClassificationService for Story 2.4-refactored</reason>
      </artifact>

      <artifact>
        <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/apps/api/src/jobs/services/layer1-domain-analysis.service.ts</path>
        <kind>service</kind>
        <symbol>Layer1DomainAnalysisService</symbol>
        <lines>1-100</lines>
        <reason>Reference implementation pattern from Story 2.3-refactored showing configuration loading, fail-open strategy, and service structure to follow for new Layer 3 services</reason>
      </artifact>

      <artifact>
        <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/apps/api/src/workers/url-worker.processor.ts</path>
        <kind>worker</kind>
        <symbol>UrlWorkerProcessor</symbol>
        <lines>1-100, 145-175</lines>
        <reason>Worker processor showing existing Layer 1 and Layer 2 integration pattern - Layer 3 classification must be integrated after Layer 2 PASS in similar pattern</reason>
      </artifact>

      <artifact>
        <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/apps/api/src/jobs/jobs.module.ts</path>
        <kind>module</kind>
        <symbol>JobsModule</symbol>
        <lines>1-58</lines>
        <reason>NestJS module where new services (ConfidenceScoringService, ManualReviewRouterService) must be registered in providers AND exports arrays</reason>
      </artifact>

      <artifact>
        <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/packages/shared/src/types/result.ts</path>
        <kind>types</kind>
        <symbol>Result, ClassificationResponse</symbol>
        <lines>1-17</lines>
        <reason>Shared types for classification results - must be extended with ConfidenceBand type and manual_review_required field</reason>
      </artifact>
    </code>

    <dependencies>
      <node>
        <package>@google/generative-ai</package>
        <version>^0.24.1</version>
        <purpose>Gemini 2.0 Flash API client for primary LLM classification</purpose>
      </node>
      <node>
        <package>openai</package>
        <version>^6.3.0</version>
        <purpose>OpenAI GPT-4o-mini API client for fallback LLM classification</purpose>
      </node>
      <node>
        <package>@supabase/supabase-js</package>
        <version>^2.39.0</version>
        <purpose>Supabase database client for persisting Layer 3 results and loading configuration</purpose>
      </node>
      <node>
        <package>bullmq</package>
        <version>^5.0.0</version>
        <purpose>Job queue system for URL processing pipeline</purpose>
      </node>
      <node>
        <package>zod</package>
        <version>^3.25.76</version>
        <purpose>Schema validation for configuration and API responses</purpose>
      </node>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint type="architecture">
      <rule>Layer 3 classification ONLY called after Layer 2 PASS - never call LLM if Layer 1 or Layer 2 eliminated URL</rule>
    </constraint>

    <constraint type="architecture">
      <rule>All services must be registered in JobsModule providers AND exports arrays for NestJS dependency injection</rule>
    </constraint>

    <constraint type="architecture">
      <rule>Use full site scraping for Layer 3 (vs homepage-only in Layer 2) for comprehensive content analysis</rule>
    </constraint>

    <constraint type="configuration">
      <rule>Load configuration from classification_settings.layer3_rules (database) with fallback to environment variables if database unavailable</rule>
    </constraint>

    <constraint type="configuration">
      <rule>NO hardcoded configuration values (timeout, models, retry delays, temperature, thresholds) - all must be externalized</rule>
    </constraint>

    <constraint type="database">
      <rule>Database migration MUST be applied to Supabase via Supabase MCP tool and verified with SELECT query before deployment</rule>
    </constraint>

    <constraint type="database">
      <rule>Preserve existing LLM fields (classification_score, classification_reasoning, llm_provider, llm_cost) - only ADD new fields (confidence_band, manual_review_required)</rule>
    </constraint>

    <constraint type="testing">
      <rule>NO skipped tests (describe.skip) - all unit tests must be implemented with &gt;85% coverage target</rule>
    </constraint>

    <constraint type="testing">
      <rule>Integration tests REQUIRED to verify Layer 3 service works with worker pipeline and database persistence</rule>
    </constraint>

    <constraint type="performance">
      <rule>Content truncation limit: 10,000 characters max to reduce LLM token usage - log warning when truncated</rule>
    </constraint>

    <constraint type="performance">
      <rule>LLM API timeout: 30 seconds max before triggering fallback or retry</rule>
    </constraint>

    <constraint type="cost">
      <rule>Gemini 2.0 Flash MUST be primary provider (33% cheaper than GPT-4o-mini) - GPT only used on fallback</rule>
    </constraint>

    <constraint type="cost">
      <rule>Cost tracking must separate Gemini vs GPT costs for accurate budget monitoring</rule>
    </constraint>

    <constraint type="error-handling">
      <rule>Retry logic: 3 attempts with exponential backoff (1s, 2s, 4s) for transient errors only</rule>
    </constraint>

    <constraint type="error-handling">
      <rule>Permanent errors (401, 400, 403) must NOT be retried - fail immediately with error message stored</rule>
    </constraint>

    <constraint type="logging">
      <rule>Enhanced error context in logs: include URL, retry count, elapsed time in all error messages</rule>
    </constraint>

    <constraint type="logging">
      <rule>Debug log when content exceeds 10K characters with original length and truncation applied</rule>
    </constraint>

    <constraint type="security">
      <rule>API key validation health check at startup - fail fast if GEMINI_API_KEY or OPENAI_API_KEY missing</rule>
    </constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>ClassificationService.classifyUrl()</name>
      <kind>method</kind>
      <signature>async classifyUrl(url: string, content: string): Promise&lt;{classification: 'suitable' | 'not_suitable', confidence: number, reasoning: string, provider: LlmProvider, cost: number, processingTimeMs: number, retryCount: number}&gt;</signature>
      <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/apps/api/src/jobs/services/llm.service.ts</path>
      <purpose>Primary LLM classification method with Gemini/GPT fallback - refactor to include confidence scoring and sophistication signals</purpose>
    </interface>

    <interface>
      <name>ConfidenceScoringService.calculateBand()</name>
      <kind>method</kind>
      <signature>calculateConfidenceBand(confidenceScore: number): 'high' | 'medium' | 'low' | 'auto_reject'</signature>
      <path>NEW - /Users/s0mebody/Desktop/dev/projects/website-scraper-project/apps/api/src/jobs/services/confidence-scoring.service.ts</path>
      <purpose>Calculate confidence band from 0-1 score using configurable thresholds (high: 0.8+, medium: 0.5-0.79, low: 0.3-0.49, reject: &lt;0.3)</purpose>
    </interface>

    <interface>
      <name>ManualReviewRouterService.shouldRoute()</name>
      <kind>method</kind>
      <signature>shouldRouteToManualReview(confidenceBand: ConfidenceBand): boolean</signature>
      <path>NEW - /Users/s0mebody/Desktop/dev/projects/website-scraper-project/apps/api/src/jobs/services/manual-review-router.service.ts</path>
      <purpose>Determine if result requires manual review based on confidence band (medium OR low → route to queue)</purpose>
    </interface>

    <interface>
      <name>SupabaseService.getClient()</name>
      <kind>method</kind>
      <signature>getClient(): SupabaseClient</signature>
      <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/apps/api/src/supabase/supabase.service.ts</path>
      <purpose>Get Supabase client for database operations - used to persist Layer 3 results with confidence_band and manual_review_required fields</purpose>
    </interface>

    <interface>
      <name>SettingsService.getSettings()</name>
      <kind>method</kind>
      <signature>async getSettings(): Promise&lt;ClassificationSettings&gt;</signature>
      <path>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/apps/api/src/settings/settings.service.ts</path>
      <purpose>Load classification settings from database (Story 3.0) including layer3_rules configuration</purpose>
    </interface>
  </interfaces>

  <tests>
    <standards>
      Testing framework: Jest with @nestjs/testing. Unit tests: &gt;85% coverage for services and utilities. Integration tests: Test module interactions (worker → services → database). E2E tests: Full Layer 3 processing flow with test database. Mock external APIs (Gemini, GPT) using nock for deterministic testing. NO skipped tests (describe.skip) allowed - all tests must be implemented.
    </standards>

    <locations>
      <location>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/apps/api/src/jobs/__tests__/*.spec.ts</location>
      <location>/Users/s0mebody/Desktop/dev/projects/website-scraper-project/apps/api/src/workers/__tests__/*.spec.ts</location>
    </locations>

    <ideas>
      <idea ac="AC1,AC3">
        Unit Test: ConfidenceScoringService.calculateBand() - Test all 4 bands (high: 0.9 → 'high', medium: 0.65 → 'medium', low: 0.4 → 'low', reject: 0.2 → 'auto_reject')
      </idea>

      <idea ac="AC5">
        Unit Test: ManualReviewRouterService.shouldRoute() - Test routing logic (high/auto_reject → false, medium/low → true)
      </idea>

      <idea ac="AC1,AC2">
        Unit Test: ClassificationService enhanced prompt generation - Verify prompt includes content marketing, SEO, and guest post signals
      </idea>

      <idea ac="AC1">
        Unit Test: Gemini → GPT fallback with confidence scoring - Mock Gemini timeout → verify GPT called with same confidence extraction logic
      </idea>

      <idea ac="AC6">
        Unit Test: Cost calculation accuracy - Verify token-based pricing for Gemini (input: $0.0003/1K, output: $0.0015/1K) vs GPT (input: $0.0005/1K, output: $0.002/1K)
      </idea>

      <idea ac="AC8">
        Unit Test: Configuration loading from database - Mock SettingsService.getSettings() → verify ClassificationService uses database config vs fallback defaults
      </idea>

      <idea ac="AC9">
        Integration Test: Layer 2 PASS → Layer 3 classification flow - URL passes Layer 2 → Full scraping → Layer 3 classification → Result stored with confidence_band and manual_review_required
      </idea>

      <idea ac="AC4">
        Integration Test: High Confidence - Strong signals → confidence 0.9 → Auto-approved as "suitable", manual_review_required = false
      </idea>

      <idea ac="AC4,AC5">
        Integration Test: Medium Confidence - Some signals → confidence 0.65 → Routed to manual review, manual_review_required = true, log entry created
      </idea>

      <idea ac="AC4,AC5">
        Integration Test: Low Confidence - Weak signals → confidence 0.4 → Routed to manual review, manual_review_required = true
      </idea>

      <idea ac="AC4">
        Integration Test: Auto-Reject - No signals → confidence 0.1 → Auto-rejected as "not_suitable", manual_review_required = false
      </idea>

      <idea ac="AC5">
        Integration Test: Manual review queue population - Verify medium/low results populate database with correct URL, confidence score, reasoning
      </idea>

      <idea ac="AC10">
        Integration Test: Cost tracking - Process 10 URLs → Verify Gemini cost vs GPT cost separated correctly in job totals
      </idea>

      <idea ac="AC10">
        Integration Test: Performance - Process 15 URLs → Verify processing rate 10-15 URLs/minute met
      </idea>

      <idea ac="AC9">
        Integration Test: Real-time dashboard updates - Verify current_layer = 3 when Layer 3 processing starts, Supabase Realtime fires on result insert
      </idea>
    </ideas>
  </tests>
</story-context>
